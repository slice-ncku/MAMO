{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truth Inference from Crowdsourcing with Optimal Return of Interest: A Strategic Macro Assignment and Micro Optimization Paradigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "- [Setup](#setup)\n",
    "    - [Import](#import)\n",
    "    - [Parameters](#parameters)\n",
    "- [MAMO](#MAMO)\n",
    "    - [Mirco](#micro)\n",
    "        - [Utility Functions](#micro-utility)\n",
    "        - [micro cp](#micro-cp)\n",
    "        - [micro greedy](#micro-greedy)\n",
    "        - [micro mckp](#micro-mckp)\n",
    "        - [micro difficulty](#micro-difficulty)\n",
    "    - [Macro](#macro)\n",
    "        - [Utility Functions](#macro-utility)\n",
    "        - [macro without multi-process](#macro-without-multi-process)\n",
    "        - [macro with multi-process](#macro-with-multi-process)\n",
    "- [Random-MAMO](#random-MAMO)\n",
    "    - [Micro](#micro-random)\n",
    "    - [Macro](#macro-random)\n",
    "- [Requallo](#requallo)\n",
    "- [Experiment](#experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name='setup'></a>\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='import'></a>\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "from faker import Faker\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from math import ceil\n",
    "from itertools import combinations\n",
    "from pprint import pprint\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import ujson\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_gen = Faker()\n",
    "fake_gen.seed(42)\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='parameters'></a>\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For micro\n",
    "ALPHA = 0.8\n",
    "MAX_ITERATION = 100\n",
    "THRESHOLD = 0.75\n",
    "\n",
    "## For difficulty\n",
    "ETA = 0.3\n",
    "\n",
    "# For macro\n",
    "SIMULATE_CNT = 5\n",
    "MAX_ROUND = 5\n",
    "CONF_THRESHOLD = 0.3\n",
    "\n",
    "# For overall setup\n",
    "max_assign_cnt = 3\n",
    "budget = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "<a name='MAMO'></a>\n",
    "# MAMO\n",
    "\n",
    "<a name='micro'></a>\n",
    "## Micro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='micro-utility'></a>\n",
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def gen_difficulty(task):\n",
    "    \"\"\"\n",
    "    利用機率的方法決定 difficulty，把 pre-confidence 的左邊跟右邊個切三段，當作標準差，\n",
    "    並在左右邊各用不同的標準差隨機 Random 出 200 個數值，在 pre-confidence 的左右邊各取 50 個數值，\n",
    "    最後在 100 個數值內隨機挑選出一個當作 difficulty。\n",
    "    Args:\n",
    "        task (dict): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json\n",
    "\n",
    "    Return:\n",
    "        float: 0 ~ 1 之間的浮點數。\n",
    "    \"\"\"\n",
    "    pre_confidence = task['pre-answer']['confidence']\n",
    "    difficulty_std_r = (1 - pre_confidence) / 3\n",
    "    difficulty_std_l = pre_confidence / 3\n",
    "    difficulty_list = list()\n",
    "\n",
    "    difficulty_2d_r = (pre_confidence + difficulty_std_r * np.random.randn(1, 200))\n",
    "    difficulty_2d_l = (pre_confidence + difficulty_std_l * np.random.randn(1, 200))\n",
    "    for difficulty in difficulty_2d_r[0]:\n",
    "        if difficulty >= pre_confidence and difficulty <= 1:\n",
    "            difficulty_list.append(difficulty)\n",
    "\n",
    "        if len(difficulty_list) == 50:\n",
    "            break\n",
    "\n",
    "    for difficulty in difficulty_2d_l[0]:\n",
    "        if difficulty >= 0 and difficulty <= pre_confidence:\n",
    "            difficulty_list.append(difficulty)\n",
    "\n",
    "        if len(difficulty_list) == 100:\n",
    "            break\n",
    "\n",
    "    difficulty = difficulty_list[random.randint(0, 99)]\n",
    "    return difficulty\n",
    "\n",
    "\n",
    "def gen_true_conf(pre_confidence, level_comb, levels_dict, answer_dict):\n",
    "    \"\"\"\n",
    "    利用 pre_confidence 以及 level_comb ，計算出在 level_comb 的組合下，\n",
    "    最後得到的 confidence 會是多少。\n",
    "\n",
    "    Args:\n",
    "        pre_confidence (float): 0 ~ 1 之間的浮點數\n",
    "        level_comb (list): worker 的組合，像是 ['level1', 'level1', 'level2'] 代表兩個 level 1 的 worker ，以及一個 level 2 的 worker\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        answer_dict (dict): 在真正的 Crowdsourcing 中， level1 及 level2 worker 的回答，可參考 Exp-Data/answers.json\n",
    "\n",
    "    Return:\n",
    "        float: 0 ~ 1 之間的浮點數\n",
    "    \"\"\"\n",
    "    true_conf_direct = pre_confidence\n",
    "    false_conf_direct = 1 - true_conf_direct\n",
    "    for level_name in level_comb:\n",
    "        random_answer_index = random.randint(0, len(answer_dict[level_name])-1)\n",
    "        answer = answer_dict[level_name][random_answer_index]\n",
    "        if answer['option'] is True:\n",
    "            true_conf_direct = true_conf_direct * levels_dict[level_name]['quality']\n",
    "            false_conf_direct = false_conf_direct * (1 - levels_dict[level_name]['quality'])\n",
    "        else:\n",
    "            true_conf_direct = true_conf_direct * (1 - levels_dict[level_name]['quality'])\n",
    "            false_conf_direct = false_conf_direct * levels_dict[level_name]['quality']\n",
    "    true_conf = true_conf_direct / (true_conf_direct + false_conf_direct)\n",
    "    return true_conf\n",
    "\n",
    "\n",
    "def calculate_expected_revenue(task, levels_dict, level_combs):\n",
    "    results = list()\n",
    "    for level_comb in level_combs:\n",
    "        gte_threshold_cnt = 0\n",
    "        cost_sum = 0\n",
    "        for level_name in level_comb:\n",
    "            cost_sum += levels_dict[level_name]['cost']\n",
    "\n",
    "        for i in range(MAX_ITERATION):\n",
    "            true_conf_direct = task['pre-answer']['confidence']\n",
    "            false_conf_direct = 1 - true_conf_direct\n",
    "\n",
    "            for level_name in level_comb:\n",
    "                true_ratio = levels_dict[level_name]['true_ratio']\n",
    "                random_float = random.uniform(0, 1)\n",
    "                if random_float <= true_ratio:\n",
    "                    true_conf_direct = true_conf_direct * levels_dict[level_name]['quality']\n",
    "                    false_conf_direct = false_conf_direct * (1 - levels_dict[level_name]['quality'])\n",
    "                else:\n",
    "                    true_conf_direct = true_conf_direct * (1 - levels_dict[level_name]['quality'])\n",
    "                    false_conf_direct = false_conf_direct * levels_dict[level_name]['quality']\n",
    "\n",
    "            true_conf = true_conf_direct / (true_conf_direct + false_conf_direct)\n",
    "            if true_conf >= THRESHOLD:\n",
    "                gte_threshold_cnt += 1\n",
    "\n",
    "        expected_revenue = gte_threshold_cnt / MAX_ITERATION * task['revenue']\n",
    "        result_dict = {\n",
    "            \"level_comb\": level_comb,\n",
    "            \"gte_threshold_cnt\": gte_threshold_cnt,\n",
    "            \"expected_revenue\": expected_revenue,\n",
    "            \"cost\": cost_sum\n",
    "        }\n",
    "        results.append(result_dict)\n",
    "    return results\n",
    "\n",
    "\n",
    "def micro_optimization(task, levels_dict, max_assign_cnt):\n",
    "    \"\"\"\n",
    "    計算 task 在有作多能指派多少 worker 的數量限制下，每一種 worker 組合能得到的 revenue 期望值各是多少。\n",
    "\n",
    "    Args:\n",
    "        task (dict): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "\n",
    "    Return:\n",
    "        list of dictionary: 每一個 dictionary 都包含 level_comb, gte_threshold_cnt, expected_revenue 以及 cost\n",
    "    \"\"\"\n",
    "    difficulty = gen_difficulty(task)\n",
    "    levels_dict['level1']['true_ratio'] = (\n",
    "        ALPHA * levels_dict['level1']['quality'] + (1 - ALPHA) * difficulty\n",
    "    )\n",
    "    levels_dict['level2']['true_ratio'] = (\n",
    "        ALPHA * levels_dict['level2']['quality'] + (1 - ALPHA) * difficulty\n",
    "    )\n",
    "\n",
    "    level1_max_assign_cnt = len(task['answers']['level1'])\n",
    "    level2_max_assign_cnt = len(task['answers']['level2'])\n",
    "    level_combs = list()\n",
    "    for total_assign_cnt in range(1, max_assign_cnt + 1):\n",
    "        for level1_assign_cnt in range(total_assign_cnt+1):\n",
    "            level2_assign_cnt = total_assign_cnt - level1_assign_cnt\n",
    "            if (level1_assign_cnt > level1_max_assign_cnt or \n",
    "                    level2_assign_cnt > level2_max_assign_cnt):\n",
    "                continue\n",
    "            level_comb = level1_assign_cnt * ['level1'] + level2_assign_cnt * ['level2']\n",
    "            level_combs.append(level_comb)\n",
    "\n",
    "    return calculate_expected_revenue(task, levels_dict, level_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='micro-cp'></a>\n",
    "### micro cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def micro_cp(tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget):\n",
    "    \"\"\"\n",
    "    先將 task 的 revenue 及 pre_confidence 相成，再由高而低的排列，從最大的 task 開始解。\n",
    "\n",
    "    Args:\n",
    "        tasks (list): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        tasks_answer_dict (dict): 在真正的 Crowdsourcing 中， level1 及 level2 worker 的回答，可參考 Exp-Data/answers.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "        budget (int): 預算\n",
    "\n",
    "    Return:\n",
    "        tasks (list): 會將每個 task 新增一個 is_solved 的值，如果已經被解掉的 task ， is_solved=True\n",
    "        output_dict (dict): 包含 revenue_sum, correct_cnt 以及 remaining_budget\n",
    "    \"\"\"\n",
    "    remaining_budget = budget\n",
    "    revenue_sum = 0\n",
    "    correct_cnt = 0\n",
    "\n",
    "    for task in tasks:\n",
    "        task['is_solved'] = False\n",
    "        task['origin_exp_revenue'] = task['pre-answer']['confidence'] * task['revenue']\n",
    "\n",
    "    tasks_order_by_origin_exp_revenue = sorted(\n",
    "        tasks, key=lambda k: k['origin_exp_revenue'], reverse=True\n",
    "    )\n",
    "    for task in tasks_order_by_origin_exp_revenue:\n",
    "        task_id = task['id']\n",
    "        pre_confidence = task['pre-answer']['confidence']\n",
    "\n",
    "        results = micro_optimization(task, levels_dict, max_assign_cnt)\n",
    "        results_order_by_cost = sorted(results, key=lambda k: k['cost'])\n",
    "        results_order_by_expected_revenue = sorted(\n",
    "            results_order_by_cost, key=lambda k: k['expected_revenue'], reverse=True\n",
    "        )\n",
    "        for result in results_order_by_expected_revenue:\n",
    "            if (remaining_budget - result['cost']) < 0:\n",
    "                continue\n",
    "\n",
    "            if result['expected_revenue'] == 0:\n",
    "                continue\n",
    "\n",
    "            true_conf = gen_true_conf(\n",
    "                pre_confidence, result['level_comb'],\n",
    "                levels_dict,\n",
    "                tasks_answer_dict[task_id]\n",
    "            )\n",
    "            task['pre-answer']['confidence'] = true_conf\n",
    "\n",
    "            if true_conf >= THRESHOLD:\n",
    "                revenue_sum += task['revenue']\n",
    "                correct_cnt += 1\n",
    "                task['is_solved'] = True\n",
    "\n",
    "            remaining_budget -= result['cost']\n",
    "            break\n",
    "\n",
    "    outcome_dict = {\n",
    "        'revenue_sum': revenue_sum,\n",
    "        'correct_cnt': correct_cnt,\n",
    "        'remaining_budget':remaining_budget\n",
    "    }\n",
    "\n",
    "    return tasks, outcome_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='micro-greedy'></a>\n",
    "### micro greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def micro_greedy(tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget):\n",
    "    \"\"\"\n",
    "    先將 task 做 revenue 由高而低的排列，從 revenue 最大的 task 開始解。\n",
    "\n",
    "    Args:\n",
    "        tasks (list): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        tasks_answer_dict (dict): 在真正的 Crowdsourcing 中， level1 及 level2 worker 的回答，可參考 Exp-Data/answers.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "        budget (int): 預算\n",
    "\n",
    "    Return:\n",
    "        tasks (list): 會將每個 task 新增一個 is_solved 的值，如果已經被解掉的 task ， is_solved=True\n",
    "        output_dict (dict): 包含 revenue_sum, correct_cnt 以及 remaining_budget\n",
    "    \"\"\"\n",
    "    remaining_budget = budget\n",
    "    revenue_sum = 0\n",
    "    correct_cnt = 0\n",
    "\n",
    "    for task in tasks:\n",
    "        task['is_solved'] = False\n",
    "\n",
    "    tasks_order_by_revenue = sorted(tasks, key=lambda k: k['revenue'], reverse=True)\n",
    "    for task in tasks_order_by_revenue:\n",
    "        task_id = task['id']\n",
    "        pre_confidence = task['pre-answer']['confidence']\n",
    "\n",
    "        results = micro_optimization(task, levels_dict, max_assign_cnt)\n",
    "        results_order_by_cost = sorted(results, key=lambda k: k['cost'])\n",
    "        results_order_by_expected_revenue = sorted(\n",
    "            results_order_by_cost, key=lambda k: k['expected_revenue'], reverse=True\n",
    "        )\n",
    "        for result in results_order_by_expected_revenue:\n",
    "            if (remaining_budget - result['cost']) < 0:\n",
    "                continue\n",
    "\n",
    "            if result['expected_revenue'] == 0:\n",
    "                continue\n",
    "\n",
    "            true_conf = gen_true_conf(\n",
    "                pre_confidence,\n",
    "                result['level_comb'],\n",
    "                levels_dict,\n",
    "                tasks_answer_dict[task_id]\n",
    "            )\n",
    "            task['pre-answer']['confidence'] = true_conf\n",
    "\n",
    "            if true_conf >= THRESHOLD:\n",
    "                revenue_sum += task['revenue']\n",
    "                correct_cnt += 1\n",
    "                task['is_solved'] = True\n",
    "\n",
    "            remaining_budget -= result['cost']\n",
    "            break\n",
    "\n",
    "    outcome_dict = {\n",
    "        'revenue_sum': revenue_sum,\n",
    "        'correct_cnt': correct_cnt,\n",
    "        'remaining_budget': remaining_budget\n",
    "    }\n",
    "    return tasks, outcome_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='micro-mckp'></a>\n",
    "### micro mckp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def micro_mckp(tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget):\n",
    "    \"\"\"\n",
    "    將我們的問題套用到多背背問題後的解法，可以參考 http://www2.lssh.tp.edu.tw/~hlf/class-1/lang-c/DP.pdf ，裡面的「P06: 分組的背包問題」。\n",
    "\n",
    "    Args:\n",
    "        tasks (list): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        tasks_answer_dict (dict): 在真正的 Crowdsourcing 中， level1 及 level2 worker 的回答，可參考 Exp-Data/answers.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "        budget (int): 預算\n",
    "\n",
    "    Return:\n",
    "        tasks (list): 會將每個 task 新增一個 is_solved 的值，如果已經被解掉的 task ， is_solved=True\n",
    "        output_dict (dict): 包含 revenue_sum, correct_cnt 以及 remaining_budget\n",
    "    \"\"\"\n",
    "    for task in tasks:\n",
    "        task['is_solved'] = False\n",
    "\n",
    "    budget_expected_revenue = [0] * (budget+1)\n",
    "    budget_expected_correct = [0] * (budget+1)\n",
    "    budget_do_tasks = list()\n",
    "    for tmp_budget in range(budget+1):\n",
    "        budget_do_tasks.append(dict())\n",
    "\n",
    "    for task in tasks:\n",
    "        task_id = task['id']\n",
    "        results = micro_optimization(task, levels_dict, max_assign_cnt)\n",
    "\n",
    "        for tmp_budget in range(budget, 0, -1):\n",
    "            for result in results:\n",
    "                cost = result['cost']\n",
    "                expected_revenue = result['expected_revenue']\n",
    "\n",
    "                if tmp_budget - cost < 0:\n",
    "                    continue\n",
    "\n",
    "                if expected_revenue == 0:\n",
    "                    continue\n",
    "\n",
    "                if (budget_expected_revenue[tmp_budget - cost] + expected_revenue > \n",
    "                        budget_expected_revenue[tmp_budget]):\n",
    "\n",
    "                    budget_expected_revenue[tmp_budget] = (\n",
    "                        budget_expected_revenue[tmp_budget - cost] + expected_revenue\n",
    "                    )\n",
    "                    budget_expected_correct[tmp_budget] = (\n",
    "                        budget_expected_correct[tmp_budget - cost] + 1\n",
    "                    )\n",
    "\n",
    "                    budget_do_tasks[tmp_budget - cost][task_id] = {\n",
    "                        \"level_comb\": result['level_comb']\n",
    "                    }\n",
    "                    budget_do_tasks[tmp_budget] = copy.deepcopy(budget_do_tasks[tmp_budget - cost])\n",
    "\n",
    "    revenue_sum = 0\n",
    "    correct_cnt = 0\n",
    "    best_budget = budget_expected_revenue.index(max(budget_expected_revenue))\n",
    "    for task in tasks:\n",
    "        if budget_do_tasks[best_budget].get(task['id']) is None:\n",
    "            continue\n",
    "        task_id = task['id']\n",
    "        pre_confidence = task['pre-answer']['confidence']\n",
    "        level_comb = budget_do_tasks[best_budget][task['id']]['level_comb']\n",
    "        true_conf = gen_true_conf(\n",
    "            pre_confidence,\n",
    "            level_comb,\n",
    "            levels_dict,\n",
    "            tasks_answer_dict[task_id]\n",
    "        )\n",
    "        task['pre-answer']['confidence'] = true_conf\n",
    "        if true_conf >= THRESHOLD:\n",
    "            revenue_sum += task['revenue']\n",
    "            correct_cnt += 1\n",
    "            task['is_solved'] = True\n",
    "\n",
    "    outcome_dict = {\n",
    "        'revenue_sum': revenue_sum,\n",
    "        'correct_cnt': correct_cnt,\n",
    "        'remaining_budget': budget - best_budget\n",
    "    }\n",
    "    return tasks, outcome_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='micro-difficulty'></a>\n",
    "### micro difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     5,
     12
    ]
   },
   "outputs": [],
   "source": [
    "def majority_voting(answers):\n",
    "    ans_counter = Counter(answers)\n",
    "    major_answer = ans_counter.most_common()[0][0]\n",
    "    return major_answer\n",
    "\n",
    "def listify_answers(task, level=1):\n",
    "    if level not in (1, 2):\n",
    "        raise ValueError('No such level')\n",
    "    \n",
    "    level_key = 'level' + str(level)\n",
    "    return [ans['option'] for ans in task['answers'][level_key]]\n",
    "\n",
    "def calculate_difficulty(all_answers, major_answer):\n",
    "    answer_num = len(all_answers)\n",
    "    different_num = len(all_answers) - all_answers.count(major_answer)\n",
    "    return different_num / answer_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def micro_optimization_difficulty(task, levels_dict, max_assign_cnt, eta=ETA):\n",
    "    \"\"\"\n",
    "    計算 task 在有作多能指派多少 worker 的數量限制下，每一種 worker 組合能得到的 revenue 期望值各是多少。\n",
    "\n",
    "    Args:\n",
    "        task (dict): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "        eat: Difficulty門檻\n",
    "\n",
    "    Return:\n",
    "        list of dictionary: 每一個 dictionary 都包含 level_comb, gte_threshold_cnt, expected_revenue 以及 cost\n",
    "    \"\"\"\n",
    "    difficulty = task['difficulty']\n",
    "    levels_dict['level1']['true_ratio'] = (\n",
    "        ALPHA * levels_dict['level1']['quality'] + (1 - ALPHA) * difficulty\n",
    "    )\n",
    "    levels_dict['level2']['true_ratio'] = (\n",
    "        ALPHA * levels_dict['level2']['quality'] + (1 - ALPHA) * difficulty\n",
    "    )\n",
    "\n",
    "    level1_max_assign_cnt = len(task['answers']['level1'])\n",
    "    level2_max_assign_cnt = len(task['answers']['level2'])\n",
    "    \n",
    "    choosen_level = 'level1' if difficulty < eta else 'level2'\n",
    "    max_assign_cnt = min(max_assign_cnt, len(task['answers'][choosen_level]))\n",
    "    level_combs = [\n",
    "        [choosen_level] * n\n",
    "        for n in range(1, max_assign_cnt+1)\n",
    "    ]\n",
    "    \n",
    "    return calculate_expected_revenue(task, levels_dict, level_combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def micro_cp_difficulty(tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tasks (list): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        tasks_answer_dict (dict): 在真正的 Crowdsourcing 中， level1 及 level2 worker 的回答，可參考 Exp-Data/answers.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "        budget (int): 預算\n",
    "\n",
    "    Return:\n",
    "        tasks (list): 會將每個 task 新增一個 is_solved 的值，如果已經被解掉的 task ， is_solved=True\n",
    "        output_dict (dict): 包含 revenue_sum, correct_cnt 以及 remaining_budget\n",
    "    \"\"\"\n",
    "    remaining_budget = budget\n",
    "    revenue_sum = 0\n",
    "    correct_cnt = 0\n",
    "\n",
    "    for task in tasks:\n",
    "        task['is_solved'] = False\n",
    "        task['origin_exp_revenue'] = task['pre-answer']['confidence'] * task['revenue']\n",
    "\n",
    "        answers = listify_answers(task)        \n",
    "        y_head = majority_voting(answers)\n",
    "        task['difficulty'] = calculate_difficulty(answers, y_head)\n",
    "        \n",
    "    tasks_order_by_origin_exp_revenue = sorted(\n",
    "        tasks,\n",
    "        key=lambda k: k['origin_exp_revenue'],\n",
    "        reverse=True\n",
    "    )\n",
    "    for task in tasks_order_by_origin_exp_revenue:\n",
    "        task_id = task['id']\n",
    "        pre_confidence = task['pre-answer']['confidence']\n",
    "\n",
    "        results = micro_optimization_difficulty(task, levels_dict, max_assign_cnt)\n",
    "        results_order_by_cost = sorted(results, key=lambda k: k['cost'])\n",
    "        results_order_by_expected_revenue = sorted(\n",
    "            results_order_by_cost,\n",
    "            key=lambda k: k['expected_revenue'],\n",
    "            reverse=True\n",
    "        )\n",
    "        for result in results_order_by_expected_revenue:\n",
    "            if (remaining_budget - result['cost']) < 0:\n",
    "                continue\n",
    "\n",
    "            if result['expected_revenue'] == 0:\n",
    "                continue\n",
    "\n",
    "            true_conf = gen_true_conf(\n",
    "                pre_confidence,\n",
    "                result['level_comb'],\n",
    "                levels_dict,\n",
    "                tasks_answer_dict[task_id]\n",
    "            )\n",
    "            task['pre-answer']['confidence'] = true_conf\n",
    "\n",
    "            if true_conf >= THRESHOLD:\n",
    "                revenue_sum += task['revenue']\n",
    "                correct_cnt += 1\n",
    "                task['is_solved'] = True\n",
    "\n",
    "            remaining_budget -= result['cost']\n",
    "            break\n",
    "\n",
    "    outcome_dict = {\n",
    "        'revenue_sum': revenue_sum,\n",
    "        'correct_cnt': correct_cnt,\n",
    "        'remaining_budget':remaining_budget\n",
    "    }\n",
    "    return tasks, outcome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def micro_greedy_difficulty(tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget):\n",
    "    \"\"\"\n",
    "    先將 task 做 revenue 由高而低的排列，從 revenue 最大的 task 開始解。\n",
    "\n",
    "    Args:\n",
    "        tasks (list): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        tasks_answer_dict (dict): 在真正的 Crowdsourcing 中， level1 及 level2 worker 的回答，可參考 Exp-Data/answers.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "        budget (int): 預算\n",
    "\n",
    "    Return:\n",
    "        tasks (list): 會將每個 task 新增一個 is_solved 的值，如果已經被解掉的 task ， is_solved=True\n",
    "        output_dict (dict): 包含 revenue_sum, correct_cnt 以及 remaining_budget\n",
    "    \"\"\"\n",
    "    remaining_budget = budget\n",
    "    revenue_sum = int()\n",
    "    correct_cnt = int()\n",
    "\n",
    "    for task in tasks:\n",
    "        task['is_solved'] = False\n",
    "\n",
    "        answers = listify_answers(task)        \n",
    "        y_head = majority_voting(answers)\n",
    "        task['difficulty'] = calculate_difficulty(answers, y_head)\n",
    "\n",
    "    tasks_order_by_revenue = sorted(tasks, key=lambda k: k['revenue'], reverse=True)\n",
    "    for task in tasks_order_by_revenue:\n",
    "        task_id = task['id']\n",
    "        pre_confidence = task['pre-answer']['confidence']\n",
    "\n",
    "        results = micro_optimization_difficulty(task, levels_dict, max_assign_cnt)\n",
    "        results_order_by_cost = sorted(results, key=lambda k: k['cost'])\n",
    "        results_order_by_expected_revenue = sorted(\n",
    "            results_order_by_cost, key=lambda k: k['expected_revenue'], reverse=True\n",
    "        )\n",
    "        for result in results_order_by_expected_revenue:\n",
    "            if (remaining_budget - result['cost']) < 0:\n",
    "                continue\n",
    "\n",
    "            if result['expected_revenue'] == 0:\n",
    "                continue\n",
    "\n",
    "            true_conf = gen_true_conf(\n",
    "                pre_confidence,\n",
    "                result['level_comb'],\n",
    "                levels_dict,\n",
    "                tasks_answer_dict[task_id]\n",
    "            )\n",
    "            task['pre-answer']['confidence'] = true_conf\n",
    "\n",
    "            if true_conf >= THRESHOLD:\n",
    "                revenue_sum += task['revenue']\n",
    "                correct_cnt += 1\n",
    "                task['is_solved'] = True\n",
    "\n",
    "            remaining_budget -= result['cost']\n",
    "            break\n",
    "\n",
    "    outcome_dict = {\n",
    "        'revenue_sum': revenue_sum,\n",
    "        'correct_cnt': correct_cnt,\n",
    "        'remaining_budget': remaining_budget\n",
    "    }\n",
    "    return tasks, outcome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def micro_mckp_difficulty(tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget):\n",
    "    \"\"\"\n",
    "    將我們的問題套用到多背背問題後的解法，可以參考 http://www2.lssh.tp.edu.tw/~hlf/class-1/lang-c/DP.pdf ，裡面的「P06: 分組的背包問題」。\n",
    "\n",
    "    Args:\n",
    "        tasks (list): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        tasks_answer_dict (dict): 在真正的 Crowdsourcing 中， level1 及 level2 worker 的回答，可參考 Exp-Data/answers.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "        budget (int): 預算\n",
    "\n",
    "    Return:\n",
    "        tasks (list): 會將每個 task 新增一個 is_solved 的值，如果已經被解掉的 task ， is_solved=True\n",
    "        output_dict (dict): 包含 revenue_sum, correct_cnt 以及 remaining_budget\n",
    "    \"\"\"\n",
    "    for task in tasks:\n",
    "        task['is_solved'] = False\n",
    "        \n",
    "        answers = listify_answers(task)        \n",
    "        y_head = majority_voting(answers)\n",
    "        task['difficulty'] = calculate_difficulty(answers, y_head)\n",
    "\n",
    "    budget_expected_revenue = [0] * (budget+1)\n",
    "    budget_expected_correct = [0] * (budget+1)\n",
    "    budget_do_tasks = list()\n",
    "    for tmp_budget in range(budget+1):\n",
    "        budget_do_tasks.append(dict())\n",
    "\n",
    "    for task in tasks:\n",
    "        task_id = task['id']\n",
    "        results = micro_optimization_difficulty(task, levels_dict, max_assign_cnt)\n",
    "\n",
    "        for tmp_budget in range(budget, 0, -1):\n",
    "            for result in results:\n",
    "                cost = result['cost']\n",
    "                expected_revenue = result['expected_revenue']\n",
    "\n",
    "                if tmp_budget - cost < 0:\n",
    "                    continue\n",
    "\n",
    "                if expected_revenue == 0:\n",
    "                    continue\n",
    "\n",
    "                if (budget_expected_revenue[tmp_budget - cost] + expected_revenue > \n",
    "                        budget_expected_revenue[tmp_budget]):\n",
    "\n",
    "                    budget_expected_revenue[tmp_budget] = (\n",
    "                        budget_expected_revenue[tmp_budget - cost] + expected_revenue\n",
    "                    )\n",
    "                    budget_expected_correct[tmp_budget] = (\n",
    "                        budget_expected_correct[tmp_budget - cost] + 1\n",
    "                    )\n",
    "\n",
    "                    budget_do_tasks[tmp_budget - cost][task_id] = {\n",
    "                        \"level_comb\": result['level_comb']\n",
    "                    }\n",
    "                    budget_do_tasks[tmp_budget] = copy.deepcopy(budget_do_tasks[tmp_budget - cost])\n",
    "\n",
    "    revenue_sum = 0\n",
    "    correct_cnt = 0\n",
    "    best_budget = budget_expected_revenue.index(max(budget_expected_revenue))\n",
    "    for task in tasks:\n",
    "        if budget_do_tasks[best_budget].get(task['id']) is None:\n",
    "            continue\n",
    "        task_id = task['id']\n",
    "        pre_confidence = task['pre-answer']['confidence']\n",
    "        level_comb = budget_do_tasks[best_budget][task['id']]['level_comb']\n",
    "        true_conf = gen_true_conf(\n",
    "            pre_confidence,\n",
    "            level_comb,\n",
    "            levels_dict,\n",
    "            tasks_answer_dict[task_id]\n",
    "        )\n",
    "        task['pre-answer']['confidence'] = true_conf\n",
    "        if true_conf >= THRESHOLD:\n",
    "            revenue_sum += task['revenue']\n",
    "            correct_cnt += 1\n",
    "            task['is_solved'] = True\n",
    "\n",
    "    outcome_dict = {\n",
    "        'revenue_sum': revenue_sum,\n",
    "        'correct_cnt': correct_cnt,\n",
    "        'remaining_budget': budget - best_budget\n",
    "    }\n",
    "    return tasks, outcome_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='macro'></a>\n",
    "## Macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='macro-utility'></a>\n",
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def macro_uniform(tasks, levels_dict, tasks_answer_dict, level_comb):\n",
    "    \"\"\"\n",
    "    將每一個 task 都分配一樣的 worker 組合\n",
    "\n",
    "    Args:\n",
    "        tasks (list): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        tasks_answer_dict (dict): 在真正的 Crowdsourcing 中， level1 及 level2 worker 的回答，可參考 Exp-Data/answers.json\n",
    "        level_comb (list): worker 的組合，像是 ['level1', 'level1', 'level2'] 代表兩個 level 1 的 worker ，以及一個 level 2 的 worker\n",
    "    Return:\n",
    "        tasks (list): 會將每個 task 新增一個 is_solved 的值，如果已經被解掉的 task ， is_solved=True\n",
    "        output_dict (dict): 包含 revenue_sum, correct_cnt 以及 remaining_budget\n",
    "    \"\"\"\n",
    "    revenue_sum = 0\n",
    "    correct_cnt = 0\n",
    "\n",
    "    for task in tasks:\n",
    "        task['is_solved'] = False\n",
    "        task['origin_exp_revenue'] = task['pre-answer']['confidence'] * task['revenue']\n",
    "\n",
    "    tasks_order_by_origin_exp_revenue = sorted(\n",
    "        tasks, key=lambda k: k['origin_exp_revenue'], reverse=True\n",
    "    )\n",
    "    for task in tasks_order_by_origin_exp_revenue:\n",
    "        task_id = task['id']\n",
    "        pre_confidence = task['pre-answer']['confidence']\n",
    "\n",
    "        true_conf = gen_true_conf(\n",
    "            pre_confidence,\n",
    "            level_comb,\n",
    "            levels_dict,\n",
    "            tasks_answer_dict[task_id]\n",
    "        )\n",
    "        task['pre-answer']['confidence'] = true_conf\n",
    "\n",
    "        if true_conf >= THRESHOLD:\n",
    "            revenue_sum += task['revenue']\n",
    "            correct_cnt += 1\n",
    "            task['is_solved'] = True\n",
    "\n",
    "    outcome_dict = {\n",
    "        'revenue_sum': revenue_sum,\n",
    "        'correct_cnt': correct_cnt,\n",
    "        'remaining_budget': 0\n",
    "    }\n",
    "    return tasks, outcome_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "def gte_threshold_filter(**kwargs):\n",
    "    return kwargs.get('new_confidence') >= CONF_THRESHOLD\n",
    "\n",
    "\n",
    "def keepup_filter(**kwargs):\n",
    "    return (kwargs.get('new_confidence') - kwargs.get('pre_confidence')) >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='macro-without-multi-process'></a>\n",
    "### Without multi-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def macro(task_filter, micro_alg,\n",
    "          tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget,\n",
    "          apply_uniform=False, uniform_initial_comb=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        task_filter (function): gte_threshold_filter, keepup_filter\n",
    "        alg (function): micro_greedy, micro_cp or micro_mckp\n",
    "        tasks (list): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        tasks_answer_dict (dict): 在真正的 Crowdsourcing 中， level1 及 level2 worker 的回答，可參考 Exp-Data/answers.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "        budget (int): 預算\n",
    "        apply_uniform (bool): 是否採用uniform strategy\n",
    "        uniform_initial_comb (list): 採用uniform strategy時的初始worker安排\n",
    "    Return:\n",
    "        macro_result (dict): 列出最後全部得到的 revenue, 答對題數, 剩餘資金，以及每一回合得到的 revenue, 答對題數以及剩餘資金\n",
    "    \"\"\"\n",
    "    macro_result = {\n",
    "        \"total_rev\": 0.0,\n",
    "        \"total_correct\": 0.0,\n",
    "        \"remaining_budget\": 0.0,\n",
    "        \"rounds\": list()\n",
    "    }\n",
    "    for _ in range(MAX_ROUND):\n",
    "        macro_result['rounds'].append({\n",
    "            \"round_rev\": 0.0,\n",
    "            \"round_correct\": 0.0,\n",
    "            \"round_remaining\": 0.0\n",
    "        })\n",
    "\n",
    "    for index in range(SIMULATE_CNT):\n",
    "        logger.info(f'Round {index+1} Start')\n",
    "        \n",
    "        total_rev = 0.0\n",
    "        total_correct = 0.0\n",
    "        remaining_budget = budget\n",
    "\n",
    "        round_tasks = copy.deepcopy(tasks)\n",
    "        tasks_dict = dict()\n",
    "        for task in tasks:\n",
    "            tasks_dict[task['id']] = copy.deepcopy(task)\n",
    "            tasks_dict[task['id']]['is_solved'] = False\n",
    "\n",
    "        for round_num in range(MAX_ROUND):\n",
    "            if apply_uniform and round_num == 0:\n",
    "                if uniform_initial_comb is None:\n",
    "                    uniform_initial_comb = [\"level1\", \"level2\"]\n",
    "                    \n",
    "                cost_sum = 0\n",
    "                for level_name in uniform_initial_comb:\n",
    "                    cost_sum += levels_dict[level_name]['cost']\n",
    "                round_budget = cost_sum * len(round_tasks)\n",
    "                result_tasks, outcome_dict = macro_uniform(\n",
    "                    round_tasks, levels_dict, tasks_answer_dict, uniform_initial_comb\n",
    "                )\n",
    "            else:\n",
    "                round_budget = int(remaining_budget/(MAX_ROUND - round_num))\n",
    "\n",
    "            result_tasks, outcome_dict = micro_alg(\n",
    "                round_tasks, levels_dict, tasks_answer_dict, max_assign_cnt, round_budget\n",
    "            )\n",
    "            next_round_tasks = list()\n",
    "            for result_task in result_tasks:\n",
    "                new_confidence = result_task['pre-answer']['confidence']\n",
    "                pre_confidence = tasks_dict[result_task['id']]['pre-answer']['confidence']\n",
    "                tasks_dict[result_task['id']]['pre-answer']['confidence'] = new_confidence\n",
    "                tasks_dict[result_task['id']]['is_solved'] = result_task['is_solved']\n",
    "                if (new_confidence < THRESHOLD and\n",
    "                        task_filter(new_confidence=new_confidence,\n",
    "                                    pre_confidence=pre_confidence)):\n",
    "                    next_round_tasks.append(result_task)\n",
    "            round_tasks = next_round_tasks\n",
    "\n",
    "            total_rev += outcome_dict['revenue_sum']\n",
    "            total_correct += outcome_dict['correct_cnt']\n",
    "            remaining_budget = remaining_budget - round_budget + outcome_dict['remaining_budget']\n",
    "\n",
    "            macro_result['rounds'][round_num]['round_rev'] += outcome_dict['revenue_sum']\n",
    "            macro_result['rounds'][round_num]['round_correct'] += outcome_dict['correct_cnt']\n",
    "            macro_result['rounds'][round_num]['round_remaining'] += remaining_budget\n",
    "        logger.info(f'Round {index+1} End')\n",
    "\n",
    "        macro_result['total_rev'] += total_rev\n",
    "        macro_result['total_correct'] += total_correct\n",
    "        macro_result['remaining_budget'] += remaining_budget\n",
    "\n",
    "    macro_result['total_rev'] /= SIMULATE_CNT\n",
    "    macro_result['total_correct'] /= SIMULATE_CNT\n",
    "    macro_result['remaining_budget'] /= SIMULATE_CNT\n",
    "    for round_num in range(MAX_ROUND):\n",
    "        macro_result['rounds'][round_num]['round_rev'] /= SIMULATE_CNT\n",
    "        macro_result['rounds'][round_num]['round_correct'] /= SIMULATE_CNT\n",
    "        macro_result['rounds'][round_num]['round_remaining'] /= SIMULATE_CNT\n",
    "    return macro_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='macro-with-multi-process'></a>\n",
    "### With multi-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def macro_simulate(task_filter, micro_alg,\n",
    "                   tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget,\n",
    "                   apply_uniform=False, uniform_initial_comb=None):\n",
    "    round_results = list()\n",
    "    for _ in range(MAX_ROUND):\n",
    "        round_results.append({\n",
    "            \"round_rev\": 0.0,\n",
    "            \"round_correct\": 0.0,\n",
    "            \"round_remaining\": 0.0\n",
    "        })\n",
    "\n",
    "    total_rev = 0.0\n",
    "    total_correct = 0.0\n",
    "    remaining_budget = budget\n",
    "\n",
    "    round_tasks = copy.deepcopy(tasks)\n",
    "    tasks_dict = dict()\n",
    "    for task in tasks:\n",
    "        tasks_dict[task['id']] = copy.deepcopy(task)\n",
    "        tasks_dict[task['id']]['is_solved'] = False\n",
    "\n",
    "    for round_num in range(MAX_ROUND):\n",
    "        if apply_uniform and round_num == 0:\n",
    "            if uniform_initial_comb is None:\n",
    "                uniform_initial_comb = [\"level1\", \"level2\"]\n",
    "                    \n",
    "            cost_sum = 0\n",
    "            for level_name in uniform_initial_comb:\n",
    "                cost_sum += levels_dict[level_name]['cost']\n",
    "            round_budget = cost_sum * len(round_tasks)\n",
    "            result_tasks, outcome_dict = macro_uniform(\n",
    "                round_tasks, levels_dict, tasks_answer_dict, uniform_initial_comb\n",
    "            )\n",
    "        else:\n",
    "            round_budget = int(remaining_budget/(MAX_ROUND - round_num))\n",
    "            \n",
    "        result_tasks, outcome_dict = micro_alg(\n",
    "            round_tasks, levels_dict, tasks_answer_dict, max_assign_cnt, round_budget\n",
    "        )\n",
    "        next_round_tasks = list()\n",
    "        for result_task in result_tasks:\n",
    "            new_confidence = result_task['pre-answer']['confidence']\n",
    "            pre_confidence = tasks_dict[result_task['id']]['pre-answer']['confidence']\n",
    "            tasks_dict[result_task['id']]['pre-answer']['confidence'] = new_confidence\n",
    "            tasks_dict[result_task['id']]['is_solved'] = result_task['is_solved']\n",
    "            if (new_confidence < THRESHOLD and\n",
    "                    task_filter(new_confidence=new_confidence,\n",
    "                                pre_confidence=pre_confidence)):\n",
    "                next_round_tasks.append(result_task)\n",
    "        round_tasks = next_round_tasks\n",
    "\n",
    "        total_rev += outcome_dict['revenue_sum']\n",
    "        total_correct += outcome_dict['correct_cnt']\n",
    "        remaining_budget = remaining_budget - round_budget + outcome_dict['remaining_budget']\n",
    "\n",
    "        round_results[round_num]['round_rev'] += outcome_dict['revenue_sum']\n",
    "        round_results[round_num]['round_correct'] += outcome_dict['correct_cnt']\n",
    "        round_results[round_num]['round_remaining'] += remaining_budget\n",
    "\n",
    "    simulate_result = {\n",
    "        \"total_rev\": total_rev,\n",
    "        \"total_correct\": total_correct,\n",
    "        \"remaining_budget\": remaining_budget,\n",
    "        \"rounds\": round_results\n",
    "    }\n",
    "    return simulate_result\n",
    "\n",
    "                \n",
    "def macro_async(task_filter, micro_alg,\n",
    "                tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget,\n",
    "                apply_uniform=False, uniform_initial_comb=None):\n",
    "    macro_result = {\n",
    "        \"total_rev\": 0.0,\n",
    "        \"total_correct\": 0.0,\n",
    "        \"remaining_budget\": 0.0,\n",
    "        \"rounds\": list()\n",
    "    }\n",
    "    for round_num in range(MAX_ROUND):\n",
    "        macro_result['rounds'].append({\n",
    "            \"round_rev\": 0.0,\n",
    "            \"round_correct\": 0.0,\n",
    "            \"round_remaining\": 0.0\n",
    "        })\n",
    "\n",
    "    pool = Pool(processes=5)\n",
    "    simulate_processes = list()\n",
    "\n",
    "    for index in range(SIMULATE_CNT):\n",
    "        logger.info(f'Async Round {index+1} Start')\n",
    "        simulate_processes.append(\n",
    "            pool.apply_async(\n",
    "                macro_simulate,\n",
    "                (task_filter, micro_alg,\n",
    "                 tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget,\n",
    "                 apply_uniform, uniform_initial_comb)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    for simulate_process in simulate_processes:\n",
    "        simulate_result = simulate_process.get()\n",
    "        logging.info(simulate_result['total_rev'])\n",
    "        macro_result['total_rev'] += simulate_result['total_rev']\n",
    "        macro_result['total_correct'] += simulate_result['total_correct']\n",
    "        macro_result['remaining_budget'] += simulate_result['remaining_budget']\n",
    "\n",
    "        for round_num in range(MAX_ROUND):\n",
    "            macro_result['rounds'][round_num]['round_rev'] += (\n",
    "                simulate_result['rounds'][round_num]['round_rev']\n",
    "            )\n",
    "            macro_result['rounds'][round_num]['round_correct'] += (\n",
    "                simulate_result['rounds'][round_num]['round_correct']\n",
    "            )\n",
    "            macro_result['rounds'][round_num]['round_remaining'] += (\n",
    "                simulate_result['rounds'][round_num]['round_remaining']\n",
    "            )\n",
    "\n",
    "    macro_result['total_rev'] /= SIMULATE_CNT\n",
    "    macro_result['total_correct'] /= SIMULATE_CNT\n",
    "    macro_result['remaining_budget'] /= SIMULATE_CNT\n",
    "    for round_num in range(MAX_ROUND):\n",
    "        macro_result['rounds'][round_num]['round_rev'] /= SIMULATE_CNT\n",
    "        macro_result['rounds'][round_num]['round_correct'] /= SIMULATE_CNT\n",
    "        macro_result['rounds'][round_num]['round_remaining'] /= SIMULATE_CNT\n",
    "    return macro_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='random-MAMO'></a>\n",
    "# Random-MAMO\n",
    "\n",
    "<a name='micro-random'></a>\n",
    "## Micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def micro_optimization_random(task, levels_dict, max_assign_cnt):\n",
    "    \"\"\"\n",
    "    隨機選擇一種worker組合，計算能得到的revenus期望值。\n",
    "\n",
    "    Args:\n",
    "        task (dict): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "\n",
    "    Return:\n",
    "        list of dictionary: 每一個 dictionary 都包含 level_comb, gte_threshold_cnt, expected_revenue 以及 cost\n",
    "    \"\"\"\n",
    "    difficulty = gen_difficulty(task)\n",
    "    levels_dict['level1']['true_ratio'] = ALPHA * levels_dict['level1']['quality'] + (1 - ALPHA) * difficulty\n",
    "    levels_dict['level2']['true_ratio'] = ALPHA * levels_dict['level2']['quality'] + (1 - ALPHA) * difficulty\n",
    "\n",
    "    available_levels = (\n",
    "        ['level1'] * len(task['answers']['level1']) +\n",
    "        ['level2'] * len(task['answers']['level2'])\n",
    "    )\n",
    "    worker_num = random.randint(1, max_assign_cnt)\n",
    "    level_combs = set(combinations(available_levels, worker_num))\n",
    "    level_combs = random.sample(level_combs, 1)\n",
    "    return calculate_expected_revenue(task, levels_dict, level_combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def micro_random(tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget):\n",
    "    \"\"\"\n",
    "    隨機選擇能解的task\n",
    "\n",
    "    Args:\n",
    "        tasks (list): 有 task 資訊的 dictonary ，可參考 Exp-Data/task.json.\n",
    "        levels_dict (dict): worker 的等級，以及 quality ，可以參考 Exp-Data/levels.json\n",
    "        tasks_answer_dict (dict): 在真正的 Crowdsourcing 中， level1 及 level2 worker 的回答，可參考 Exp-Data/answers.json\n",
    "        max_assign_cnt (int): 最多能指派多少 worker\n",
    "        budget (int): 預算\n",
    "\n",
    "    Return:\n",
    "        tasks (list): 會將每個 task 新增一個 is_solved 的值，如果已經被解掉的 task ， is_solved=True\n",
    "        output_dict (dict): 包含 revenue_sum, correct_cnt 以及 remaining_budget\n",
    "    \"\"\"\n",
    "    remaining_budget = budget\n",
    "    revenue_sum = 0\n",
    "    correct_cnt = 0\n",
    "\n",
    "    for task in tasks:\n",
    "        task['is_solved'] = False\n",
    "\n",
    "    random.shuffle(tasks)\n",
    "    for task in tasks:\n",
    "        task_id = task['id']\n",
    "        pre_confidence = task['pre-answer']['confidence']\n",
    "\n",
    "        results = micro_optimization_random(task, levels_dict, max_assign_cnt)\n",
    "        for result in results:\n",
    "            if (remaining_budget - result['cost']) < 0:\n",
    "                continue\n",
    "\n",
    "            if result['expected_revenue'] == 0:\n",
    "                continue\n",
    "\n",
    "            true_conf = gen_true_conf(\n",
    "                pre_confidence, result['level_comb'],\n",
    "                levels_dict,\n",
    "                tasks_answer_dict[task_id]\n",
    "            )\n",
    "            task['pre-answer']['confidence'] = true_conf\n",
    "\n",
    "            if true_conf >= THRESHOLD:\n",
    "                revenue_sum += task['revenue']\n",
    "                correct_cnt += 1\n",
    "                task['is_solved'] = True\n",
    "\n",
    "            remaining_budget -= result['cost']\n",
    "            break\n",
    "\n",
    "    outcome_dict = {\n",
    "        'revenue_sum': revenue_sum,\n",
    "        'correct_cnt': correct_cnt,\n",
    "        'remaining_budget':remaining_budget\n",
    "    }\n",
    "\n",
    "    return tasks, outcome_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='macro-random'></a>\n",
    "## Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def macro_random(tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget):\n",
    "    macro_result = {\n",
    "        \"total_rev\": 0.0,\n",
    "        \"total_correct\": 0.0,\n",
    "        \"remaining_budget\": 0.0,\n",
    "        \"rounds\": list()\n",
    "    }\n",
    "    for _ in range(MAX_ROUND):\n",
    "        macro_result['rounds'].append({\n",
    "            \"round_rev\": 0.0,\n",
    "            \"round_correct\": 0.0,\n",
    "            \"round_remaining\": 0.0\n",
    "        })\n",
    "\n",
    "    for index in range(SIMULATE_CNT):\n",
    "        logger.info(f'Round {index+1} Start')\n",
    "        \n",
    "        total_rev = 0.0\n",
    "        total_correct = 0.0\n",
    "        remaining_budget = budget\n",
    "\n",
    "        round_tasks = copy.deepcopy(tasks)\n",
    "        tasks_dict = dict()\n",
    "        for task in tasks:\n",
    "            tasks_dict[task['id']] = copy.deepcopy(task)\n",
    "            tasks_dict[task['id']]['is_solved'] = False\n",
    "\n",
    "        for round_num in range(MAX_ROUND):\n",
    "            round_budget = int(remaining_budget/(MAX_ROUND - round_num))\n",
    "\n",
    "            result_tasks, outcome_dict = micro_random(\n",
    "                round_tasks, levels_dict, tasks_answer_dict, max_assign_cnt, round_budget\n",
    "            )\n",
    "            next_round_tasks = list()\n",
    "            for result_task in result_tasks:\n",
    "                new_confidence = result_task['pre-answer']['confidence']\n",
    "                pre_confidence = tasks_dict[result_task['id']]['pre-answer']['confidence']\n",
    "                tasks_dict[result_task['id']]['pre-answer']['confidence'] = new_confidence\n",
    "                tasks_dict[result_task['id']]['is_solved'] = result_task['is_solved']\n",
    "                if (new_confidence < THRESHOLD and fake_gen.boolean()):\n",
    "                    next_round_tasks.append(result_task)\n",
    "            round_tasks = next_round_tasks\n",
    "\n",
    "            total_rev += outcome_dict['revenue_sum']\n",
    "            total_correct += outcome_dict['correct_cnt']\n",
    "            remaining_budget = remaining_budget - round_budget + outcome_dict['remaining_budget']\n",
    "\n",
    "            macro_result['rounds'][round_num]['round_rev'] += outcome_dict['revenue_sum']\n",
    "            macro_result['rounds'][round_num]['round_correct'] += outcome_dict['correct_cnt']\n",
    "            macro_result['rounds'][round_num]['round_remaining'] += remaining_budget\n",
    "        logger.info(f'Round {index+1} End')\n",
    "\n",
    "        macro_result['total_rev'] += total_rev\n",
    "        macro_result['total_correct'] += total_correct\n",
    "        macro_result['remaining_budget'] += remaining_budget\n",
    "\n",
    "    macro_result['total_rev'] /= SIMULATE_CNT\n",
    "    macro_result['total_correct'] /= SIMULATE_CNT\n",
    "    macro_result['remaining_budget'] /= SIMULATE_CNT\n",
    "    for round_num in range(MAX_ROUND):\n",
    "        macro_result['rounds'][round_num]['round_rev'] /= SIMULATE_CNT\n",
    "        macro_result['rounds'][round_num]['round_correct'] /= SIMULATE_CNT\n",
    "        macro_result['rounds'][round_num]['round_remaining'] /= SIMULATE_CNT\n",
    "    return macro_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='requallo'></a>\n",
    "# Requallo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class BayesianRequallo:\n",
    "    \"\"\"bayesian requirement\"\"\"\n",
    "    \n",
    "    def __init__(self, tasks, levels_dict, tasks_answer_dict, budget):\n",
    "        self.levels_dict = levels_dict\n",
    "        self.tasks_answer_dict = tasks_answer_dict\n",
    "        \n",
    "        self.solved_tasks = list()\n",
    "        self.unsolved_tasks = deepcopy(tasks)\n",
    "        self.skipped_tasks = list()\n",
    "        self.budget = budget\n",
    "    \n",
    "    def run(self):\n",
    "        while self.budget > 0:\n",
    "            logger.debug(f'-----Iteration start-----')\n",
    "\n",
    "            max_reward, max_index = -1, None\n",
    "            for index, task in enumerate(self.unsolved_tasks):\n",
    "                reward = self._compute_reward(task)\n",
    "                \n",
    "                if reward > max_reward:\n",
    "                    max_reward = reward\n",
    "                    max_index = index\n",
    "                    \n",
    "            if not (max_reward > 0):\n",
    "                logger.info(f'No reward is greater than 0')\n",
    "                break\n",
    "\n",
    "            choosen_task = self.unsolved_tasks[max_index]\n",
    "            \n",
    "            # Random choose a worker that is affordable\n",
    "            affordabale_groups = [\n",
    "                group_name\n",
    "                for group_name in task['answers']\n",
    "                if self.budget >= self.levels_dict[group_name]['cost'] and choosen_task['answers'][group_name]\n",
    "            ]\n",
    "                \n",
    "            if affordabale_groups:\n",
    "                group_name = random.sample(affordabale_groups, 1)[0]\n",
    "                new_label = random.sample(choosen_task['answers'][group_name], 1)[0]\n",
    "                new_label_cost = self.levels_dict[group_name]['cost']\n",
    "            else:\n",
    "                logger.warning(f'Label for task {choosen_task} is consumed.')\n",
    "                \n",
    "                # Force the requriement to be met since no label can be retrieved\n",
    "                \n",
    "                self.skipped_tasks.append(choosen_task)\n",
    "                self.unsolved_tasks.remove(choosen_task)\n",
    "                continue\n",
    "            \n",
    "            self.budget -= new_label_cost\n",
    "            if self.budget < 0:\n",
    "                self.budget += new_label_cost\n",
    "                logger.info(f'Out of budget.')\n",
    "                break\n",
    "            \n",
    "            # ------\n",
    "            if 'choosen_labels' not in choosen_task:\n",
    "                choosen_task['choosen_labels'] = {\n",
    "                    'level1': [], \n",
    "                    'level2': []\n",
    "                }\n",
    "                \n",
    "            choosen_task['choosen_labels'][group_name].append(new_label)\n",
    " \n",
    "            choosen_task['answers'][group_name].remove(new_label)\n",
    "            # ------\n",
    "        \n",
    "            if self._check_task_met_requirement(choosen_task):\n",
    "                choosen_task['is_solved'] = True\n",
    "                \n",
    "                # -------\n",
    "                self.solved_tasks.append(choosen_task)\n",
    "                self.unsolved_tasks.remove(choosen_task)\n",
    "                # -------\n",
    "                                \n",
    "            logger.debug(f'-----Iteration end-----')\n",
    "        logger.info(f'Final Remaining Budget: {self.budget}')\n",
    "        return self.all_tasks\n",
    "            \n",
    "    @property\n",
    "    def all_tasks(self):\n",
    "        return self.solved_tasks[:] + self.unsolved_tasks[:]\n",
    "    \n",
    "    def _compute_reward(self, task):\n",
    "        \"\"\"R(S^t, i^t) = P(y_{i^t} = +1)R_{i^t}^{+1} + P(y_{i^t} = -1)R_{i^t}^{-1} \"\"\"\n",
    "        true_label_count, false_label_count = self._calculate_count(task)\n",
    "        current_value = self._compute_expected_completeness(true_label_count, false_label_count)\n",
    "        \n",
    "        level2_label_quality = self.levels_dict['level2']['quality']\n",
    "        reward_add_true = (\n",
    "            self._compute_expected_completeness(\n",
    "                true_label_count*level2_label_quality,\n",
    "                false_label_count*(1 - level2_label_quality)\n",
    "            ) +\n",
    "            current_value\n",
    "        )\n",
    "        reward_add_false = (\n",
    "            self._compute_expected_completeness(\n",
    "                true_label_count*(1-level2_label_quality),\n",
    "                false_label_count*level2_label_quality\n",
    "            ) +\n",
    "            current_value\n",
    "        )\n",
    "        return max(reward_add_true, reward_add_false)\n",
    "    \n",
    "    def _calculate_count(self, task):\n",
    "        pre_confidence = task['pre-answer']['confidence']\n",
    "        true_count, false_count = pre_confidence, 1 - pre_confidence\n",
    "        \n",
    "        if 'choosen_labels' in task:\n",
    "            for level_name, labels in task['choosen_labels'].items():\n",
    "                quality = self.levels_dict[level_name]['quality']\n",
    "                for label in labels:\n",
    "                    if label['option'] is True:\n",
    "                        true_count *= quality\n",
    "                        false_count *= (1 - quality)\n",
    "                    else:\n",
    "                        true_count *= (1 - quality)\n",
    "                        false_count *= quality\n",
    "        return true_count, false_count\n",
    "    \n",
    "    def _compute_expected_completeness(self, true_label_count, false_label_count):\n",
    "        \"\"\"V_i(a_i, b_i)\"\"\"\n",
    "        \n",
    "        total_label_num = true_label_count + false_label_count\n",
    "        if total_label_num == 0:\n",
    "            return 0\n",
    "\n",
    "        return (\n",
    "            self._compute_difficulty_level(true_label_count, false_label_count) *\n",
    "            (total_label_num)/self._compute_required_label_num(true_label_count, false_label_count)\n",
    "            +\n",
    "            self._compute_difficulty_level(false_label_count, true_label_count) *\n",
    "            (total_label_num)/self._compute_required_label_num(false_label_count, true_label_count)\n",
    "        )     \n",
    "    \n",
    "    def _compute_difficulty_level(self, expected_label_count, opposite_label_count):\n",
    "        \"\"\"P(Z_i = + 1 | a_i, b_i)\"\"\"\n",
    "        \n",
    "        total_label_num = expected_label_count + opposite_label_count\n",
    "        \n",
    "        if expected_label_count == opposite_label_count:\n",
    "            return 0.5\n",
    "        else:\n",
    "            ratio_of_expected_labels = expected_label_count/total_label_num\n",
    "            \n",
    "            if expected_label_count > opposite_label_count:\n",
    "                #  a_i / (a_i + b_i) + b_i / r(b_i)\n",
    "                return (\n",
    "                    ratio_of_expected_labels +\n",
    "                    opposite_label_count/self._compute_required_label_num(expected_label_count, opposite_label_count)\n",
    "                )\n",
    "            else:\n",
    "                # a_i / (a_i + b_i) - a_i / r(a_i)\n",
    "                return (\n",
    "                    ratio_of_expected_labels +\n",
    "                    expected_label_count/self._compute_required_label_num(opposite_label_count, expected_label_count)\n",
    "                )\n",
    "            \n",
    "    def _compute_required_label_num(self, expected_label_count, opposite_label_count):\n",
    "        \"\"\"r(a_i, bi|Z_i) >= c\n",
    "        \n",
    "        r(a_i) = r(b_i, a_i|Z_i = -1)\n",
    "        r(b_i) = r(a_i, b_i|Z_i = +1)\n",
    "        \"\"\"\n",
    "        if expected_label_count == 0:\n",
    "            expected_label_count = 0.25\n",
    "        \n",
    "        level2_label_quality = self.levels_dict['level2']['quality']\n",
    "        num = 1\n",
    "        const = (\n",
    "            (opposite_label_count * THRESHOLD) /\n",
    "            ((1-THRESHOLD) * expected_label_count)\n",
    "        )\n",
    "        while level2_label_quality ** num < (1 - level2_label_quality) ** num * const:\n",
    "            num += 1\n",
    "        return level2_label_quality**num * expected_label_count\n",
    "\n",
    "    def _check_task_met_requirement(self, task):\n",
    "        true_label_count, false_label_count = self._calculate_count(task)\n",
    "        return self._check_requirement(true_label_count, false_label_count)\n",
    "        # if true_label_count > false_label_count:\n",
    "        #     return self._check_requirement(true_label_count, false_label_count)\n",
    "        # else:\n",
    "        #     return self._check_requirement(false_label_count, true_label_count)\n",
    "        \n",
    "    def _check_requirement(self, expected_label_count, opposite_label_count):\n",
    "        return expected_label_count/(expected_label_count+opposite_label_count) >= THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class BayesianRequalloWithRevenueReward:\n",
    "    \"\"\"bayesian requirement with revenue reward\"\"\"\n",
    "    \n",
    "    def __init__(self, tasks, levels_dict, tasks_answer_dict, budget):\n",
    "        self.levels_dict = levels_dict\n",
    "        self.tasks_answer_dict = tasks_answer_dict\n",
    "        \n",
    "        self.solved_tasks = list()\n",
    "        self.unsolved_tasks = deepcopy(tasks)\n",
    "        self.skipped_tasks = list()\n",
    "        self.budget = budget\n",
    "    \n",
    "    def run(self):\n",
    "        while self.budget > 0:\n",
    "            logger.debug(f'-----Iteration start-----')\n",
    "\n",
    "            max_reward, max_index = -1, None\n",
    "            for index, task in enumerate(self.unsolved_tasks):\n",
    "                reward = self._compute_reward(task)\n",
    "                \n",
    "                if reward > max_reward:\n",
    "                    max_reward = reward\n",
    "                    max_index = index\n",
    "                    \n",
    "            if not (max_reward > 0):\n",
    "                logger.debug(f'No reward is greater than 0')\n",
    "                break\n",
    "\n",
    "            choosen_task = self.unsolved_tasks[max_index]\n",
    "            \n",
    "            # Random choose a worker that is affordable\n",
    "            affordabale_groups = [\n",
    "                group_name\n",
    "                for group_name in task['answers']\n",
    "                if self.budget >= self.levels_dict[group_name]['cost'] and choosen_task['answers'][group_name]\n",
    "            ]\n",
    "                \n",
    "            if affordabale_groups:\n",
    "                group_name = random.sample(affordabale_groups, 1)[0]\n",
    "                new_label = random.sample(choosen_task['answers'][group_name], 1)[0]\n",
    "                new_label_cost = self.levels_dict[group_name]['cost']\n",
    "            else:\n",
    "                logger.debug(f'Label for task {choosen_task} is consumed.')\n",
    "                \n",
    "                # Force the requriement to be met since no label can be retrieved\n",
    "                \n",
    "                self.skipped_tasks.append(choosen_task)\n",
    "                self.unsolved_tasks.remove(choosen_task)\n",
    "                continue\n",
    "            \n",
    "            self.budget -= new_label_cost\n",
    "            if self.budget < 0:\n",
    "                self.budget += new_label_cost\n",
    "                logger.debug(f'Out of budget.')\n",
    "                break\n",
    "            \n",
    "            # ------\n",
    "            if 'choosen_labels' not in choosen_task:\n",
    "                choosen_task['choosen_labels'] = {\n",
    "                    'level1': [], \n",
    "                    'level2': []\n",
    "                }\n",
    "            choosen_task['choosen_labels'][group_name].append(new_label)\n",
    "            choosen_task['answers'][group_name].remove(new_label)\n",
    "            # ------\n",
    "        \n",
    "            if self._check_task_met_requirement(choosen_task):\n",
    "                choosen_task['is_solved'] = True\n",
    "                \n",
    "                # -------\n",
    "                self.solved_tasks.append(choosen_task)\n",
    "                self.unsolved_tasks.remove(choosen_task)\n",
    "                # -------\n",
    "                                \n",
    "            logger.debug(f'-----Iteration end-----')\n",
    "        logger.debug(f'Final Remaining Budget: {self.budget}')\n",
    "        return self.all_tasks\n",
    "            \n",
    "    @property\n",
    "    def all_tasks(self):\n",
    "        return self.solved_tasks[:] + self.unsolved_tasks[:]\n",
    "    \n",
    "    def _compute_reward(self, task):\n",
    "        \"\"\"R(S^t, i^t) = P(y_{i^t} = +1)R_{i^t}^{+1} + P(y_{i^t} = -1)R_{i^t}^{-1} \"\"\"\n",
    "        true_label_count, false_label_count = self._calculate_count(task)\n",
    "        current_value = self._compute_expected_completeness(true_label_count, false_label_count)\n",
    "        \n",
    "        level2_label_quality = self.levels_dict['level2']['quality']\n",
    "        reward_add_true = (\n",
    "            self._compute_expected_completeness(\n",
    "                true_label_count*level2_label_quality,\n",
    "                false_label_count*(1 - level2_label_quality)\n",
    "            ) +\n",
    "            current_value\n",
    "        )\n",
    "        return reward_add_true * task['revenue']\n",
    "    \n",
    "    def _calculate_count(self, task):\n",
    "        pre_confidence = task['pre-answer']['confidence']\n",
    "        true_count, false_count = pre_confidence, 1 - pre_confidence\n",
    "        \n",
    "        if 'choosen_labels' in task:\n",
    "            for level_name, labels in task['choosen_labels'].items():\n",
    "                quality = self.levels_dict[level_name]['quality']\n",
    "                for label in labels:\n",
    "                    if label['option'] is True:\n",
    "                        true_count *= quality\n",
    "                        false_count *= (1 - quality)\n",
    "                    else:\n",
    "                        true_count *= (1 - quality)\n",
    "                        false_count *= quality\n",
    "        return true_count, false_count\n",
    "    \n",
    "    def _compute_expected_completeness(self, true_label_count, false_label_count):\n",
    "        \"\"\"V_i(a_i, b_i)\"\"\"\n",
    "        \n",
    "        total_label_num = true_label_count + false_label_count\n",
    "        if total_label_num == 0:\n",
    "            return 0\n",
    "\n",
    "        return (\n",
    "            self._compute_difficulty_level(true_label_count, false_label_count) *\n",
    "            (total_label_num)/self._compute_required_label_num(true_label_count, false_label_count)\n",
    "        )     \n",
    "    \n",
    "    def _compute_difficulty_level(self, expected_label_count, opposite_label_count):\n",
    "        \"\"\"P(Z_i = + 1 | a_i, b_i)\"\"\"\n",
    "        \n",
    "        total_label_num = expected_label_count + opposite_label_count\n",
    "        \n",
    "        if expected_label_count == opposite_label_count:\n",
    "            return 0.5\n",
    "        else:\n",
    "            ratio_of_expected_labels = expected_label_count/total_label_num\n",
    "            \n",
    "            if expected_label_count > opposite_label_count:\n",
    "                #  a_i / (a_i + b_i) + b_i / r(b_i)\n",
    "                return (\n",
    "                    ratio_of_expected_labels +\n",
    "                    opposite_label_count/self._compute_required_label_num(expected_label_count, opposite_label_count)\n",
    "                )\n",
    "            else:\n",
    "                # a_i / (a_i + b_i) - a_i / r(a_i)\n",
    "                return (\n",
    "                    ratio_of_expected_labels +\n",
    "                    expected_label_count/self._compute_required_label_num(opposite_label_count, expected_label_count)\n",
    "                )\n",
    "            \n",
    "    def _compute_required_label_num(self, expected_label_count, opposite_label_count):\n",
    "        \"\"\"r(a_i, bi|Z_i) >= c\n",
    "        \n",
    "        r(a_i) = r(b_i, a_i|Z_i = -1)\n",
    "        r(b_i) = r(a_i, b_i|Z_i = +1)\n",
    "        \"\"\"\n",
    "        if expected_label_count == 0:\n",
    "            expected_label_count = 0.25\n",
    "        \n",
    "        level2_label_quality = self.levels_dict['level2']['quality']\n",
    "        num = 1\n",
    "        const = (\n",
    "            (opposite_label_count * THRESHOLD) /\n",
    "            ((1-THRESHOLD) * expected_label_count)\n",
    "        )\n",
    "        while level2_label_quality ** num < (1 - level2_label_quality) ** num * const:\n",
    "            num += 1\n",
    "        return level2_label_quality**num * expected_label_count\n",
    "\n",
    "    def _check_task_met_requirement(self, task):\n",
    "        true_label_count, false_label_count = self._calculate_count(task)\n",
    "        confidence = (true_label_count / (true_label_count+false_label_count))\n",
    "\n",
    "        return confidence >= THRESHOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name='experiment'></a>\n",
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_file_path = 'Exp-Data/task.json'\n",
    "worker_file_path = 'Exp-Data/levels.json'\n",
    "answer_file_path = 'Exp-Data/answers.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(task_file_path, \"r\") as myfile:\n",
    "    tasks = ujson.load(myfile)\n",
    "\n",
    "with open(worker_file_path, \"r\") as myfile:\n",
    "    levels_dict = ujson.load(myfile)\n",
    "\n",
    "with open(answer_file_path, \"r\") as myfile:\n",
    "    tasks_answer_dict = ujson.load(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tasks = sorted(tasks, key=lambda x: x['revenue'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Experiment Start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random MAMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Random')\n",
    "result = {\n",
    "    'method_name': 'random-MAMO'\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    macro_result = macro_random(tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget)\n",
    "except Exception as e:\n",
    "    result['result'] = str(e)\n",
    "else:\n",
    "    result['result'] = macro_result\n",
    "result['time'] = time.time() - start_time \n",
    "experiment_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MICRO_NAME_MAPPING = {\n",
    "    micro_cp.__name__: 'Greedy-R',\n",
    "    micro_greedy.__name__: 'Greedy-PR',\n",
    "    micro_mckp.__name__: 'DP',\n",
    "    micro_cp_difficulty.__name__: 'Greedy-R-Difficulty',\n",
    "    micro_greedy_difficulty.__name__: 'Greedy-PR-Difficulty',\n",
    "    micro_mckp_difficulty.__name__: 'DP-Difficulty'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACRO_NAME_MAPPING = {\n",
    "    gte_threshold_filter.__name__: 'ASCC',\n",
    "    keepup_filter.__name__: 'ASMIC'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "available_micro_algorithms = [ \n",
    "    micro_cp,\n",
    "    micro_greedy,   \n",
    "    micro_mckp,\n",
    "    micro_cp_difficulty,\n",
    "    micro_greedy_difficulty,\n",
    "    micro_mckp_difficulty,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "available_macro_filters = [\n",
    "    gte_threshold_filter,\n",
    "    keepup_filter,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for macro_filter in available_macro_filters:\n",
    "    for apply_uniform in [\n",
    "        True, \n",
    "        False\n",
    "    ]:\n",
    "        for micro_algorithm in available_micro_algorithms:\n",
    "            method_name = (\n",
    "                f'{MICRO_NAME_MAPPING[micro_algorithm.__name__]}'\n",
    "                f'_{MACRO_NAME_MAPPING[macro_filter.__name__]}'\n",
    "            )\n",
    "            if apply_uniform:\n",
    "                method_name += '_uniform'\n",
    "                \n",
    "            logging.info(method_name)\n",
    "            result = {\n",
    "                'method_name': method_name\n",
    "            }\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                macro_result = macro_async(\n",
    "                    macro_filter, micro_algorithm,\n",
    "                    tasks, levels_dict, tasks_answer_dict, max_assign_cnt, budget,\n",
    "                    apply_uniform\n",
    "                )\n",
    "            except Exception as e:\n",
    "                result['result'] = str(e)\n",
    "            else:\n",
    "                result['result'] = macro_result\n",
    "            result['time'] = time.time() - start_time \n",
    "            experiment_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requallo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_requallo_implementations = [\n",
    "    BayesianRequalloWithRevenueReward,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for requallo_cls in available_requallo_implementations:\n",
    "    logger.info(requallo_cls.__name__)\n",
    "    result = {\n",
    "        'method_name': 'Bayesian-Requallo',\n",
    "        \"result\": {\n",
    "            \"total_rev\": 0,\n",
    "            \"total_correct\": 0,\n",
    "            \"remaining_budget\": 0,\n",
    "            \"rounds\":[]\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for index in range(5):\n",
    "        logger.info(f'Round {index+1} Start')\n",
    "        requallo = requallo_cls(tasks, levels_dict, tasks_answer_dict, budget)\n",
    "        requallo.run()\n",
    "        \n",
    "        result['result']['total_rev'] += sum([task['revenue'] for task in requallo.solved_tasks])\n",
    "        result['result']['total_correct'] += len(requallo.solved_tasks)\n",
    "        result['result']['remaining_budget'] += requallo.budget\n",
    "        logger.info(f'Round {index+1} End')\n",
    "        \n",
    "        \n",
    "    result['result']['total_rev'] /= SIMULATE_CNT\n",
    "    result['result']['total_correct'] /= SIMULATE_CNT\n",
    "    result['result']['remaining_budget'] /= SIMULATE_CNT\n",
    "\n",
    "    experiment_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in experiment_results:\n",
    "    print(\n",
    "        result['result']['total_rev'],\n",
    "        '\\t',\n",
    "        result['method_name'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_experiment_result = sorted(experiment_results, key=lambda x: x['result']['total_rev'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in sorted_experiment_result:\n",
    "    print(\n",
    "        result['result']['total_rev'],\n",
    "        '\\t',\n",
    "        result['method_name'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_filename = f'result-{max_assign_cnt}-{budget}-{int(ETA*10)}.json'\n",
    "with open(result_filename, 'w') as result_file:\n",
    "    ujson.dump(experiment_results, result_file, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
